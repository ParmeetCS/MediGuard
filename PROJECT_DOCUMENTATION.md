# ğŸ“š MediGuard Drift AI - Project Documentation

## ğŸ“‹ Table of Contents
- [Project Overview](#project-overview)
- [Workflows](#workflows)
- [Tech Stack](#tech-stack)
- [APIs & Services](#apis--services)
- [Architecture](#architecture)

---

## ğŸ¯ Project Overview

**MediGuard Drift AI** is an intelligent health monitoring platform that combines computer vision-based activity tracking with a sophisticated multi-agent AI system to detect, analyze, and respond to subtle health changes over time.

### Key Capabilities
- ğŸ“¹ **Vision-Based Activity Tracking** - Real-time movement analysis
- ğŸ¤– **Multi-Agent AI System** - 5-agent pipeline for health insights
- ğŸ“Š **Health Drift Detection** - Statistical analysis of health trends
- ğŸ’¬ **AI Health Chat** - Conversational health assistant
- ğŸ” **Secure Authentication** - Privacy-protected health records

---

## ğŸ”„ Workflows

### 1ï¸âƒ£ **User Onboarding Workflow**
```
Sign Up â†’ Email Verification â†’ Profile Setup â†’ Context Input â†’ First Health Check
```

**Steps:**
1. User creates account (email + password)
2. Supabase sends verification email
3. User completes health profile
4. User provides lifestyle context (sleep, stress, diet)
5. User performs first daily health check

---

### 2ï¸âƒ£ **Daily Health Check Workflow**
```
Login â†’ Activity Selection â†’ Camera/Video Upload â†’ Movement Analysis â†’ Results Display â†’ Data Storage
```

**Steps:**
1. **Login**: User authenticates via Supabase
2. **Activity Selection**: Choose from 3 activities:
   - Sit-to-Stand Test (10 seconds)
   - Stability Test (10 seconds)
   - Movement Speed Test (10 seconds)
3. **Recording**: 
   - **Option A**: Live camera (WebRTC)
   - **Option B**: Upload pre-recorded video
4. **Analysis**: Extract movement features using OpenCV
5. **Results**: Display metrics (speed, stability, smoothness)
6. **Storage**: Save to Supabase database

**Metrics Tracked:**
- Movement Speed
- Stability Score
- Motion Smoothness
- Posture Deviation
- Range of Motion

---

### 3ï¸âƒ£ **AI Analysis Workflow (Multi-Agent Pipeline)**

#### **High-Level Flow**
```
Health Data â†’ Orchestrator â†’ Agent Pipeline â†’ Response Synthesis â†’ User Display
```

#### **Detailed Agent Processing Flow**

```mermaid
graph TD
    A[User Health Data] --> B[Orchestrator]
    B --> C[Drift Agent]
    C --> D[Context Agent]
    D --> E[Risk Agent]
    E --> F[Safety Agent]
    F --> G[Care Agent]
    G --> H[Response Synthesis]
    H --> I[User Interface]
```

**Step-by-Step Agent Execution:**

**1. Drift Agent** ğŸ”
```
Input: Current + Historical Health Metrics
Process:
  â”œâ”€ Calculate metric changes (Î” values)
  â”œâ”€ Compute statistical significance
  â”œâ”€ Identify trends (improving/declining/stable)
  â””â”€ Generate drift report
Output: Numerical drift analysis
```

**Responsibilities:**
- Compare current vs previous health metrics
- Calculate percentage changes
- Detect statistically significant deviations
- Classify drift severity (minor/moderate/major)

**Example Output:**
```json
{
  "movement_speed": {"change": -8%, "trend": "declining", "severity": "moderate"},
  "stability": {"change": -4%, "trend": "declining", "severity": "minor"}
}
```

---

**2. Context Agent** ğŸ§ 
```
Input: Drift Report + User Context Data
Process:
  â”œâ”€ Fetch lifestyle factors (sleep, stress, diet)
  â”œâ”€ Correlate changes with context
  â”œâ”€ Identify potential causes
  â””â”€ Generate explanation
Output: Contextual analysis
```

**Responsibilities:**
- Analyze sleep patterns
- Evaluate stress levels
- Review dietary changes
- Consider environmental factors
- Correlate lifestyle with health changes

**Example Output:**
```json
{
  "likely_causes": ["Poor sleep (5 hrs)", "High stress (8/10)"],
  "correlations": {"sleep_quality": -0.7, "stress_level": 0.6}
}
```

---

**3. Risk Agent** âš ï¸
```
Input: Drift Report + Context Analysis
Process:
  â”œâ”€ Evaluate temporal patterns
  â”œâ”€ Assess trend velocity
  â”œâ”€ Calculate risk score
  â””â”€ Determine urgency level
Output: Risk assessment
```

**Responsibilities:**
- Analyze rate of change
- Evaluate trend persistence
- Assess cumulative risk
- Determine intervention urgency
- Classify concern level (low/medium/high)

**Example Output:**
```json
{
  "risk_score": 6.5,
  "urgency": "medium",
  "concern_level": "moderate",
  "trend_velocity": "accelerating"
}
```

---

**4. Safety Agent** ğŸ›¡ï¸
```
Input: All Previous Agent Outputs
Process:
  â”œâ”€ Apply ethical guardrails
  â”œâ”€ Check escalation criteria
  â”œâ”€ Evaluate medical necessity
  â””â”€ Generate safety recommendation
Output: Safety decision
```

**Responsibilities:**
- Determine if medical consultation needed
- Apply ethical guidelines
- Ensure responsible recommendations
- Flag critical conditions
- Prevent harmful advice

**Example Output:**
```json
{
  "medical_consultation": "recommended",
  "urgency": "within 48 hours",
  "red_flags": ["persistent decline", "multiple metrics affected"]
}
```

---

**5. Care Agent** ğŸ’š
```
Input: All Agent Outputs
Process:
  â”œâ”€ Synthesize all insights
  â”œâ”€ Generate actionable recommendations
  â”œâ”€ Personalize language
  â””â”€ Create user-friendly response
Output: Final care guidance
```

**Responsibilities:**
- Create unified response
- Generate actionable steps
- Personalize recommendations
- Use empathetic language
- Provide specific guidance

**Example Output:**
```
"Your movement speed has decreased by 8% over the past week. This appears 
related to reduced sleep (5 hours vs your usual 7 hours) and increased stress.

Recommendations:
1. Prioritize 7-8 hours of sleep tonight
2. Try 10-minute relaxation exercises
3. Consider consulting your doctor if decline continues
4. Monitor your progress over next 3 days"
```

---

### 4ï¸âƒ£ **AI Chat Workflow**

#### **Complete Chat Processing Flow**
```
User Input â†’ Intent Recognition â†’ Data Retrieval â†’ AI Processing â†’ 
Pattern Matching â†’ Response Generation â†’ Visualization â†’ Display
```

**Detailed Steps:**

**Step 1: User Input Processing**
```
Input: User question
Process:
  â”œâ”€ Clean and normalize text
  â”œâ”€ Extract intent
  â””â”€ Identify required data
```

**Step 2: Health Data Retrieval**
```
Query Supabase:
  â”œâ”€ Fetch user health records
  â”œâ”€ Get context data
  â”œâ”€ Retrieve historical trends
  â””â”€ Load user profile
```

**Step 3: Context Building**
```
Build AI Context:
  â”œâ”€ Format health data
  â”œâ”€ Add user information
  â”œâ”€ Include conversation history
  â””â”€ Attach system instructions
```

**Step 4: Gemini AI Processing**
```
Send to Gemini:
  â”œâ”€ User question + context
  â”œâ”€ Model: gemini-2.5-flash
  â”œâ”€ Temperature: 0.8
  â””â”€ Max tokens: 4096
```

**Step 5: Pattern Matching**
```
Check for common patterns:
  â”œâ”€ Trend queries â†’ Generate chart
  â”œâ”€ Comparison queries â†’ Show table
  â”œâ”€ Advice queries â†’ List recommendations
  â””â”€ General queries â†’ Text response
```

**Step 6: Response Enhancement**
```
Enhance response:
  â”œâ”€ Add visualizations (Plotly charts)
  â”œâ”€ Include data tables
  â”œâ”€ Format with markdown
  â””â”€ Add emoji for readability
```

**Example Chat Flows:**

**Query Type 1: Trend Analysis**
```
User: "How is my stability trending?"
  â†“
Fetch: Last 7 days stability data
  â†“
AI: Analyze trend pattern
  â†“
Generate: Line chart + summary
  â†“
Display: "Your stability has improved 5% this week! ğŸ“ˆ"
```

**Query Type 2: Factor Analysis**
```
User: "What affects my balance?"
  â†“
Fetch: Health + context data
  â†“
AI: Correlate factors
  â†“
Generate: Factor analysis
  â†“
Display: "Sleep quality (70% correlation), Stress (45% correlation)"
```

---

### 5ï¸âƒ£ **Data Storage Workflow**

#### **Complete Data Pipeline**
```
Activity Completion â†’ Feature Extraction â†’ Validation â†’ 
Transformation â†’ Database Insert â†’ Confirmation â†’ Cache Update
```

**Detailed Data Flow:**

**Step 1: Feature Extraction**
```
Input: Video frames (numpy arrays)
Process:
  â”œâ”€ Frame-by-frame motion analysis
  â”œâ”€ Calculate movement metrics
  â”œâ”€ Compute statistical features
  â””â”€ Generate feature vector
Output: Movement features dict
```

**Features Extracted:**
- Movement speed (0-1 scale)
- Stability score (0-1 scale)
- Motion smoothness (0-1 scale)
- Posture deviation (0-1 scale)
- Micro-movements (0-1 scale)
- Range of motion (0-1 scale)
- Acceleration variance
- Frame count

**Step 2: Data Validation**
```
Pydantic Validation:
  â”œâ”€ Check data types
  â”œâ”€ Validate ranges (0-1)
  â”œâ”€ Ensure required fields
  â””â”€ Sanitize inputs
```

**Step 3: Data Transformation**
```
Transform for storage:
  â”œâ”€ Add user_id
  â”œâ”€ Add timestamp
  â”œâ”€ Format as JSON
  â””â”€ Prepare metadata
```

**Step 4: Database Insert**
```
Supabase Insert:
  â”œâ”€ Connect to database
  â”œâ”€ Insert into health_records table
  â”œâ”€ Handle conflicts
  â””â”€ Return insert ID
```

**Step 5: Confirmation**
```
User Feedback:
  â”œâ”€ Display success message
  â”œâ”€ Show saved metrics
  â”œâ”€ Update UI state
  â””â”€ Clear form data
```

---

### 6ï¸âƒ£ **Video Processing Workflow**

#### **Live Camera (WebRTC)**
```
Camera Permission â†’ WebRTC Connection â†’ Frame Capture â†’ 
Processing â†’ Analysis â†’ Display Results
```

**Detailed Steps:**

**Step 1: WebRTC Setup**
```
Initialize:
  â”œâ”€ Load ICE servers from secrets
  â”œâ”€ Configure STUN/TURN
  â”œâ”€ Create WebRTC context
  â””â”€ Request camera permission
```

**Step 2: Connection Establishment**
```
Connect:
  â”œâ”€ Try STUN servers (Google)
  â”œâ”€ Fallback to TURN (Metered.ca)
  â”œâ”€ Establish peer connection
  â””â”€ Start video stream
```

**Step 3: Frame Capture**
```
Recording:
  â”œâ”€ Capture frames at 30 FPS
  â”œâ”€ Sample every 3rd frame
  â”œâ”€ Convert to RGB
  â””â”€ Store in memory
```

**Step 4: Processing**
```
Analysis:
  â”œâ”€ Extract movement features
  â”œâ”€ Calculate metrics
  â””â”€ Generate results
```

#### **Video Upload (Fallback)**
```
File Upload â†’ Temporary Storage â†’ Frame Extraction â†’ 
Processing â†’ Cleanup â†’ Display Results
```

**Detailed Steps:**

**Step 1: File Upload**
```
Upload:
  â”œâ”€ Accept MP4/AVI/MOV/WEBM
  â”œâ”€ Validate file size (<50MB)
  â”œâ”€ Check format
  â””â”€ Load into memory
```

**Step 2: Temporary Storage**
```
Save:
  â”œâ”€ Create temp file
  â”œâ”€ Write video data
  â””â”€ Get file path
```

**Step 3: Frame Extraction**
```
Extract with OpenCV:
  â”œâ”€ Open video file
  â”œâ”€ Read frames sequentially
  â”œâ”€ Sample every 3rd frame
  â”œâ”€ Convert BGR â†’ RGB
  â””â”€ Store in array
```

**Step 4: Processing**
```
Analyze:
  â”œâ”€ Run feature extraction
  â”œâ”€ Calculate metrics
  â””â”€ Generate results
```

**Step 5: Cleanup**
```
Cleanup:
  â”œâ”€ Delete temp file
  â”œâ”€ Clear memory
  â””â”€ Release resources
```

---

### 7ï¸âƒ£ **Error Handling Workflow**

#### **WebRTC Connection Failure**
```
Connection Timeout â†’ Display Warning â†’ 
Offer Upload Option â†’ User Choice â†’ Alternative Flow
```

**Handling:**
1. Detect timeout (>30 seconds)
2. Show warning message
3. Enable upload checkbox
4. Guide user to alternative
5. Process uploaded video

#### **Database Error**
```
Insert Failure â†’ Retry Logic â†’ 
Fallback Storage â†’ User Notification
```

**Handling:**
1. Catch database exception
2. Retry insert (max 3 times)
3. Log error details
4. Notify user
5. Offer manual retry

#### **AI Processing Error**
```
API Failure â†’ Check Error Type â†’ 
Apply Fallback â†’ Return Graceful Response
```

**Handling:**
1. Catch Gemini API error
2. Check error type (quota/network/safety)
3. Use fallback response
4. Log for debugging
5. Inform user gracefully

---

## ğŸ› ï¸ Tech Stack

### **Frontend**
| Technology | Purpose | Company |
|------------|---------|---------|
| **Streamlit** | Web framework | Snowflake Inc. |
| **Plotly** | Interactive charts | Plotly Technologies |
| **Matplotlib** | Data visualization | NumFOCUS |

### **Backend & Database**
| Technology | Purpose | Company |
|------------|---------|---------|
| **Supabase** | Database + Auth | Supabase Inc. |
| **Python 3.x** | Core language | Python Software Foundation |
| **python-dotenv** | Environment config | Open Source |

### **Computer Vision**
| Technology | Purpose | Company |
|------------|---------|---------|
| **OpenCV** | Video processing | OpenCV Foundation |
| **streamlit-webrtc** | Live camera | Open Source |
| **av** | Video codec | PyAV |
| **NumPy** | Numerical computing | NumFOCUS |
| **Pillow** | Image processing | Open Source |

### **AI & Machine Learning**
| Technology | Purpose | Company |
|------------|---------|---------|
| **Google Gemini AI** | Language model | Google DeepMind |
| **google-generativeai** | Gemini SDK | Google |
| **Pydantic** | Data validation | Pydantic Services |

### **Utilities**
| Technology | Purpose | Company |
|------------|---------|---------|
| **requests** | HTTP library | Open Source |
| **reportlab** | PDF generation | ReportLab |
| **pdf2image** | PDF processing | Open Source |

---

## ğŸ”Œ APIs & Services

### 1ï¸âƒ£ **Google Gemini API**
**Provider:** Google DeepMind  
**Purpose:** AI-powered health chat and analysis

**Features Used:**
- Natural language understanding
- Context-aware responses
- Multi-turn conversations
- Structured output generation

**Model:** `gemini-2.5-flash`

**Configuration:**
```python
GOOGLE_API_KEY = "your_api_key"
Model: gemini-2.5-flash
Temperature: 0.8
Max Tokens: 4096
```

**Endpoints:**
- `generateContent` - Single prompt
- `startChat` - Multi-turn conversation

---

### 2ï¸âƒ£ **Supabase API**
**Provider:** Supabase Inc.  
**Purpose:** Database, authentication, and storage

**Services Used:**
- **Authentication**: Email/password auth
- **Database**: PostgreSQL with real-time
- **Storage**: User health records

**Configuration:**
```python
SUPABASE_URL = "your_project_url"
SUPABASE_ANON_KEY = "your_anon_key"
```

**Tables:**
- `users` - User profiles
- `health_records` - Daily check results
- `user_context` - Lifestyle data

**API Methods:**
- `auth.sign_up()` - User registration
- `auth.sign_in_with_password()` - Login
- `table().insert()` - Save data
- `table().select()` - Fetch data

---

### 3ï¸âƒ£ **WebRTC (streamlit-webrtc)**
**Provider:** Open Source  
**Purpose:** Real-time camera access in browser

**Features:**
- Live video streaming
- Frame capture
- Person detection overlay

**TURN/STUN Servers:**
- Google STUN: `stun.l.google.com:19302`
- Metered.ca TURN: `global.relay.metered.ca`

**Configuration:**
```python
rtc_configuration = {
    "iceServers": [
        {"urls": ["stun:stun.l.google.com:19302"]},
        {"urls": ["turn:global.relay.metered.ca:80"], 
         "username": "...", "credential": "..."}
    ]
}
```

---

### 4ï¸âƒ£ **OpenCV API**
**Provider:** OpenCV Foundation  
**Purpose:** Video processing and feature extraction

**Features Used:**
- Video capture (`VideoCapture`)
- Frame processing
- Color conversion (BGR â†” RGB)
- Motion analysis (frame differencing)

**Key Functions:**
```python
cv2.VideoCapture() - Camera access
cv2.cvtColor() - Color conversion
cv2.imread() - Image loading
```

---

## ğŸ—ï¸ Architecture

### **System Architecture**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    User Interface                        â”‚
â”‚                    (Streamlit)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 â”‚                 â”‚
        â–¼                 â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Vision     â”‚  â”‚   AI Agent   â”‚  â”‚     Auth     â”‚
â”‚   System     â”‚  â”‚   Pipeline   â”‚  â”‚   System     â”‚
â”‚  (OpenCV)    â”‚  â”‚  (Gemini)    â”‚  â”‚ (Supabase)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                 â”‚                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   Database   â”‚
                  â”‚  (Supabase)  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Data Flow**
```
User Input â†’ Camera/Upload â†’ OpenCV Processing â†’ 
Feature Extraction â†’ Supabase Storage â†’ 
AI Analysis â†’ Gemini Processing â†’ User Response
```

### **Project Structure**
```
MediGuard/
â”œâ”€â”€ app.py                    # Main entry point
â”œâ”€â”€ requirements.txt          # Dependencies
â”‚
â”œâ”€â”€ agents/                   # AI agent system
â”‚   â”œâ”€â”€ orchestrator.py      # Agent coordination
â”‚   â”œâ”€â”€ drift_agent.py       # Drift detection
â”‚   â”œâ”€â”€ context_agent.py     # Context analysis
â”‚   â”œâ”€â”€ risk_agent.py        # Risk assessment
â”‚   â”œâ”€â”€ safety_agent.py      # Safety checks
â”‚   â”œâ”€â”€ care_agent.py        # Care recommendations
â”‚   â””â”€â”€ adk_runtime.py       # Gemini integration
â”‚
â”œâ”€â”€ pages/                    # Streamlit pages
â”‚   â”œâ”€â”€ daily_health_check.py
â”‚   â”œâ”€â”€ dashboard.py
â”‚   â”œâ”€â”€ ai_health_chat.py
â”‚   â””â”€â”€ profile.py
â”‚
â”œâ”€â”€ storage/                  # Data layer
â”‚   â”œâ”€â”€ database.py
â”‚   â”œâ”€â”€ health_repository.py
â”‚   â””â”€â”€ context_repository.py
â”‚
â”œâ”€â”€ vision/                   # Computer vision
â”‚   â”œâ”€â”€ camera.py
â”‚   â”œâ”€â”€ feature_extraction.py
â”‚   â””â”€â”€ person_detection.py
â”‚
â””â”€â”€ auth/                     # Authentication
    â””â”€â”€ supabase_auth.py
```

---

## ğŸ“Š Feature Comparison

| Feature | Local Mode | Cloud Mode |
|---------|------------|------------|
| Camera Access | OpenCV | WebRTC |
| Video Upload | âœ… | âœ… |
| Person Detection | âœ… | âŒ |
| Frame Rate | 30 FPS | Variable |
| Latency | Low | Medium |

---

## ğŸ” Security & Privacy

- **Encryption**: HTTPS for all data transmission
- **Authentication**: Supabase JWT tokens
- **Data Isolation**: User-specific records
- **Privacy**: No data sharing with third parties
- **Compliance**: Healthcare data sensitivity

---

## ğŸ“ˆ Performance Metrics

- **Frame Processing**: ~30 FPS (local), ~15 FPS (cloud)
- **Analysis Time**: 2-3 seconds per activity
- **AI Response**: 1-2 seconds average
- **Database Query**: <100ms
- **Video Upload**: Supports up to 50MB

---

## ğŸš€ Deployment

**Platform:** Streamlit Cloud  
**URL:** https://mediguard-feb6sybhmnworzdxmyngid.streamlit.app

**Environment Variables:**
- `SUPABASE_URL`
- `SUPABASE_ANON_KEY`
- `GOOGLE_API_KEY`
- `STREAMLIT_APP_URL`
- `VISION_API_KEY`
- `VISION_MODEL`

---

## ğŸ“ Version History

- **v2.0.0** (Dec 2024) - Multi-agent AI system, WebRTC support
- **v1.0.0** (Nov 2024) - Initial release

---

**Last Updated:** December 24, 2024  
**Status:** Active Development  
**License:** [Specify License]
